#!/usr/bin/env python3
"""
ì‹¤ì œ ìƒˆë¡œìš´ ì‹œê·¸ë„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
ìºì‹œë¥¼ ì‚­ì œí•˜ì—¬ ìƒˆë¡œìš´ ì‹œê·¸ë„ì´ ë°œìƒí•œ ìƒí™©ì„ ì‹œë®¬ë ˆì´ì…˜
"""

import sqlite3
from perplexity_analyzer import StockAnalyzer, get_cached_analysis

DB_FILE = "stock_data.db"

def delete_cache(ticker, date):
    """íŠ¹ì • ìºì‹œ ì‚­ì œ"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute("DELETE FROM perplexity_analysis WHERE ticker = ? AND date = ?", (ticker, date))
    deleted = cursor.rowcount
    conn.commit()
    conn.close()
    return deleted

def test_real_new_signal():
    """ì‹¤ì œ ìƒˆë¡œìš´ ì‹œê·¸ë„ ë°œìƒ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("ğŸ§ª ì‹¤ì œ ìƒˆë¡œìš´ ì‹œê·¸ë„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
    print("="*80)

    ticker = "META"
    date = "2025-12-02"
    signal = "WARNING"

    print(f"\nì‹œë‚˜ë¦¬ì˜¤: {ticker}ì—ì„œ {date}ì— ìƒˆë¡œìš´ {signal} ì‹œê·¸ë„ ë°œìƒ")
    print("-"*80)

    # 1. ê¸°ì¡´ ìºì‹œ ì‚­ì œ
    print("\nğŸ“Œ Step 1: ê¸°ì¡´ ìºì‹œ ì‚­ì œ (ìƒˆë¡œìš´ ì‹œê·¸ë„ ë°œìƒ ì‹œë®¬ë ˆì´ì…˜)")
    deleted = delete_cache(ticker, date)
    print(f"  ğŸ—‘ï¸  {deleted}ê°œ ìºì‹œ ì‚­ì œë¨")

    # 2. ìºì‹œ í™•ì¸
    print("\nğŸ“Œ Step 2: ìºì‹œ í™•ì¸")
    cached = get_cached_analysis(ticker, date)
    if cached:
        print(f"  âŒ ìºì‹œê°€ ì—¬ì „íˆ ìˆìŒ (ë¬¸ì œ!)")
        return False
    else:
        print(f"  âœ… ìºì‹œ ì—†ìŒ (ì •ìƒ) - Streamlit ì•±ì—ì„œ 'ìƒˆë¡œìš´ ì‹œê·¸ë„' ê²½ê³ ê°€ í‘œì‹œë  ê²ƒì„")

    # 3. ìƒˆë¡œìš´ ë¶„ì„ ìˆ˜í–‰
    print("\nğŸ“Œ Step 3: ì‚¬ìš©ìê°€ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ í´ë¦­ (ì‹œë®¬ë ˆì´ì…˜)")
    print("  ğŸ” AI ë¶„ì„ ì‹œì‘...")

    analyzer = StockAnalyzer()
    result = analyzer.analyze_stock_price_movement(
        ticker=ticker,
        date=date,
        signal_type=signal
    )

    if result['success']:
        is_cached = result.get('cached', False)
        print(f"  âœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"     - ìƒíƒœ: {'ìºì‹œë¨' if is_cached else 'ì‹ ê·œ ì¡°íšŒ'}")
        print(f"     - API í˜¸ì¶œ: {'ì•„ë‹ˆì˜¤' if is_cached else 'ì˜ˆ'}")

        print(f"\n  ğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print("  " + "-"*76)
        lines = result['analysis'].split('\n')
        for line in lines[:5]:  # ì²« 5ì¤„ë§Œ í‘œì‹œ
            print(f"  {line}")
        if len(lines) > 5:
            print(f"  ... ({len(lines) - 5}ì¤„ ë”)")
        print("  " + "-"*76)

        if result.get('citations'):
            print(f"\n  ğŸ“š ì°¸ê³  ìë£Œ: {len(result['citations'])}ê°œ")
    else:
        print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error')}")
        return False

    # 4. ìºì‹œ ì €ì¥ í™•ì¸
    print("\nğŸ“Œ Step 4: ìºì‹œ ì €ì¥ í™•ì¸")
    cached = get_cached_analysis(ticker, date)
    if cached:
        print(f"  âœ… ìºì‹œ ì €ì¥ë¨!")
        print(f"     - ë‹¤ìŒ ì¡°íšŒë¶€í„°ëŠ” ì¦‰ì‹œ í‘œì‹œë¨")
    else:
        print(f"  âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨ (ë¬¸ì œ!)")
        return False

    # 5. Streamlit ë™ì‘ ì‹œë®¬ë ˆì´ì…˜
    print("\nğŸ“Œ Step 5: Streamlit ì•± ë™ì‘ ì‹œë®¬ë ˆì´ì…˜")
    print("  ğŸ”„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ í›„...")

    cached = get_cached_analysis(ticker, date)
    if cached:
        print(f"  âœ… ìºì‹œëœ ê²°ê³¼ê°€ ìë™ìœ¼ë¡œ í‘œì‹œë¨")
        print(f"     - 'âœ… ë¶„ì„ ì™„ë£Œ (ìºì‹œë¨)' ë©”ì‹œì§€")
        print(f"     - ë²„íŠ¼ ì—†ì´ ì¦‰ì‹œ ë¶„ì„ ê²°ê³¼ í‘œì‹œ")
        print(f"     - API í˜¸ì¶œ ì—†ìŒ")
    else:
        print(f"  âŒ ë¬¸ì œ ë°œìƒ")
        return False

    # ìµœì¢… ìš”ì•½
    print("\n" + "="*80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    print("="*80)
    print("\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ì™„ë£Œ:")
    print("  1. âœ… ìƒˆë¡œìš´ ì‹œê·¸ë„ ê°ì§€ (ìºì‹œ ì—†ìŒ)")
    print("  2. âœ… ì‚¬ìš©ìì—ê²Œ 'ìƒˆë¡œìš´ ì‹œê·¸ë„' ê²½ê³  í‘œì‹œ")
    print("  3. âœ… ë²„íŠ¼ í´ë¦­ ì‹œ AI ë¶„ì„ ìˆ˜í–‰")
    print("  4. âœ… ë¶„ì„ ê²°ê³¼ ìë™ ìºì‹±")
    print("  5. âœ… ë‹¤ìŒ ì¡°íšŒë¶€í„° ì¦‰ì‹œ í‘œì‹œ")

    print("\nğŸ‰ ìƒˆë¡œìš´ ì‹œê·¸ë„ì´ ë°œìƒí•˜ë©´ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤!")

    return True

if __name__ == "__main__":
    success = test_real_new_signal()
    exit(0 if success else 1)
